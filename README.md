The jupyter notebook creates convolutional neural network of using architects from **simplest** only single dense layer to network with **2 convolutional layers** alongwith max pooling. This notebook is implemented to see effects with various **architects** on the accuracies on train and test set of well-known **MNIST dataset**.<br> 

It also shows the so-called **bottle neck effect** when number of filters chosen in the second convolutional layers are less than first layer. The **backpropagation shuts off many filters in first layer** in this case as the second layer acts as bottle neck. This is also major reason that commonly used architects like VGG, MobileNets have the features that the number of filters increase as move deeper into the network. In this notebook, i try to find a reason for such a choice. Even though in **Simonyan et. al. 2014**, the authors comment as the reason for this is to prevent the loss of information. 
